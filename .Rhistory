install.packages("KernSmooth")
library("KernSmooth")
install.packages("swirl")
x<-$L
x<-4L
class(x)
x
x<-c(4,TRUE)
class(x)
x
x<-c(1,3,5)
y<-c(3,2,10)
cbind(x,y)
x <- list(2, "a", "b", TRUE)
x[[2]]
class(x[[2]])
x <- 1:4
y <- 2:3
x+y
class(x+y)
x <- c(3, 5, 1, 10, 12, 6)
x[x==0]<-6
x
x[<=5]<-0
x[x==0]<6
x
x[x>=6] <-0
x
x <- c(3, 5, 1, 10, 12, 6)
x
x[x<=5]<-0
x
pwd
getwd()
cd\
dir
ls
getdir
getdir()
getls()
setwd("Users\omkarudipi\Google Drive\Personal\Coursera")
setwd("Users/omkarudipi/Google Drive/Personal/Coursera")
setwd("Users/omkarudipi/"Google Drive"/Personal/Coursera")
pwd()
getwd()
mydata <- read.csv("hw1_data.csv")
names(mydata)
head(mydata,2)
nrow(mydata)
tail(mydata,2)
mydata[152]
mydata[152,]
mydata[47,]
which(is.na(mydata$Ozone))
lenght(which(is.na(mydata$Ozone)))
length(which(is.na(mydata$Ozone)))
mean(mydata$Ozone)
mean(mydata$Ozone, na.rm= TRUE)
mydata
mydata[Ozone>10]
mydata[152,]
mydata[[$Ozone>10],]
mydata[[mydata$Ozone>10],]
y<-mydata[[mydata$Ozone>10],]
subset(mydata,Ozone>31)
subset(mydata,Ozone>31 AND 1=1)
subset(mydata,Ozone>31)
subset(mydata,Ozone>31 & Temp > 90)
mean(subset(mydata,Ozone>31 & Temp > 90), na.rm = TRUE)
mean(subset(mydata,Ozone>31 & Temp > 90))
subset(mydata,Ozone>31 & Temp > 90)
y <=subset(mydata,Ozone>31 & Temp > 90)
mean(y)
mean(y, na.rm = TRUE)
mean(y$Solar.R, na.rm = TRUE)
y
y <=subset(mydata,Ozone>31 & Temp > 90)
y
subset(mydata,Ozone>31 & Temp > 90)
mydata
ss <- mydata[with(mydata, Ozone>31 & Temp>90),]
ss
mean(ss$Solar.R)
mean(mydata,rm.na)
mean(mydata,na.rm=TRUE)
mean(mydata$Ozone,na.rm=TRUE)
mean(ss$Solar.R,na.rm=TRUE)
s2 <- mydata[mydata$Month==6,]
s2
mean(s2$Temp, na.rm=TRUE)
s3<-mydata[mydata$Month==5,]
s3
max(s3$Ozone, na.rm=TRUE)
library(datasets)
data(iris)
?iris
iris
x <- list(a =1:5,b=rnorm(10)
)
x
iris$Sepal.Length
lapply(x,mean)
y <- list(iris$Sepal.length)
y
$y
y[1]
y[0]
lapply(y,mean)
lapply(iris.Sepal.Length,mean)
lapply(iris$Sepal.Length,mean)
?runif
sapply(iris$Sepal.Length,mean)
?sapply
sapply(iris$Sepal.Length,mean, simplify=TRUE)
sapply(iris$Sepal.Length,mean, simplify=FALSE)
sapply(iris$Sepal.Length,mean, simplify=TRUE)
?mean
mean(iris$Sepal.Length, na.rm=TRUE, ARG)
x1<- c(rnorm(10), runif(10), rnorm(10,1))
f<- gl(3,10)
split(x,f)
split(x1,f)
f
x1
split(iris$Sepal.Length,species)
names(iris)
split(iris$Sepal.Length,Species)
split(iris$Sepal.Length,iris$Species)
lapply(split(iris$Sepal.Length,iris$Species), mean)
iris
?apply
apply(iris[, 1:4], 2, mean)
liraty(datasets)
library(datasets)
data(mtcars)
?mtcars
head(mtcars)
split(mtcars$mpg, mtcars$cyl)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
mtcars
sapply(split(mtcars$hp, mtcars$cyl), mean)
u <-sapply(split(mtcars$hp, mtcars$cyl), mean)
u[1]
u$4
u$[4]
u[1] - u[3]
debug(ls)
ls
?ls
/
\
?ls
ls
undebug(ls)
undebug(ls)
q
}
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
ww <- makeVector(1)
ww
ww <- makeVector(c(1,2,3))
ww
ww <- makeVector()
ww
ww$get
ww$get(1)
ww$get()
ww$getmean()
mean(ww$get())
ww <- makeVector(c(1,2,3))
mean(ww$get())
ww$getmean()
cachemean(ww)
cachemean(ww)
m <- matrix(c(1,2,3,5),nrow=2,ncol=2)
m
solve(m)
m <- matrix(c(1,2,3,4),nrow=2,ncol=2)
solve(m)
m <- matrix(c(1,2,3,4,5,6,7,8,9),nrow=3,ncol=3)
solve(m)
list(ww)
ww$list
ww$get
ww$get()
ww$getmean()
ww$list()
ww$list(set)
makeCacheMatrix <- function(x = matrix())
{
invmat <- NULL
setoriginalmatrix <- function(y)
{
orgmat <<- y
invmat <<- NULL
}
getoriginalmatrix <- function()
{
orgmat
}
setinversematrix <- function(matx)
{
invmat <<- matx
}
getinversematrix <- function()
{
invmat
}
list(setoriginalmatrix = setoriginalmatrix,
getoriginalmatrix = getoriginalmatrix,
setinversematrix = setinversematrix,
getinversematrix = getinversematrix)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...)
{
## Return a matrix that is the inverse of 'x'
m <- x$getinversematrix()
if(!is.null(m))
{
message("getting cached inverse matrix")
return(m)
}
data <- x$getoriginalmatrix()
m <- solve(data, ...) ## assumption - matrix is always invertible (requirement)
x$setinversematrix(m)
m
}
mm <- makeCacheMatrix(matrix(c(1,2,3,5), nrow(2),ncol(2)))
mm$getoriginalmatrix()
## Put comments here that give an overall description of what your
## functions do
## Write a short comment describing this function
makeCacheMatrix <- function(orgmat = matrix())
{
invmat <- NULL
setoriginalmatrix <- function(y)
{
orgmat <<- y
invmat <<- NULL
}
getoriginalmatrix <- function()
{
orgmat
}
setinversematrix <- function(matx)
{
invmat <<- matx
}
getinversematrix <- function()
{
invmat
}
list(setoriginalmatrix = setoriginalmatrix,
getoriginalmatrix = getoriginalmatrix,
setinversematrix = setinversematrix,
getinversematrix = getinversematrix)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...)
{
## Return a matrix that is the inverse of 'x'
m <- x$getinversematrix()
if(!is.null(m))
{
message("getting cached inverse matrix")
return(m)
}
data <- x$getoriginalmatrix()
m <- solve(data, ...) ## assumption - matrix is always invertible (requirement)
x$setinversematrix(m)
m
}
mm <- makeCacheMatrix(matrix(c(1,2,3,5), nrow(2),ncol(2)))
mm$getoriginalmatrix()
matrix(c(1,2,3,5), nrow(2),ncol(2))
mm <- makeCacheMatrix(matrix(c(1,2,3,5), nrow=2,ncol=2))
mm$getoriginalmatrix()
mm$getinversematrix()
cacheSolve(mm)
mm$getinversematrix()
mm$getoriginalmatrix()
mm$list
mm$list()
fileURL <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileURL, destfile = "cameras.csv", method = "curl")
list.files("")
list.files(".")
install.packages("httpuv")
install.packages("jsonlite")
?fromJSON
??fromJSON
install.packages("sqldf")
?download.file
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile="./Google Drive/Personal/Coursera/Quiz/Course3Quiz2Qn2.csv", method="curl")
x <- read.csv("./Google Drive/Personal/Coursera/Quiz/Course3Quiz2Qn2.csv")
head(x)
names(x)
library(sqldf)
?sqldf
x$acs
x$acss
x$pwgtp1
names(x$pwgtp1)
acs <- x
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1,AGEP from acs where AGEP < 50")
sqldf("select pwgtp1,AGEP from acs where AGEP < 10")
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
x1<-NULL
rm(x1)
rm(ww)
rm(u)
rm(f)
rm(ss)
rm(s3)
rm(s2)
rm(m)
?text
?points
?lines
?panel.lmline
?lmline
library(lattice)
?panel.lmline
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
?print.trellis
?par
?trellis.par.set
?splom
library(datasets)
data(airquality)
head(airquality)
str(airquality)
qplot(Wind, Ozone, data = airquality)
library(ggplot)
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
?geom
??geom
?ggplot
data(movies)
library(ggplot2)
g<-ggplot(movies, aes(votes,rating))
g
pring(g)
d
;
)
print(g)
?geom_point
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
install.packages("swirl")
library(swirl)
swirl()
bye()
install_from_swirl("Getting and Cleaning Data")
swirl()
bye()
bye()
exit
exit()
bye
library(knitr)
install.packages("knitr")
getwd()
setwd("./Google Drive/Personal/Coursera/Assignments")
getls()
ls
ls()
setwd("Users/omkarudipi"
)
setwd("/Users/omkarudipi")
setwd("./git")
setwd("./RepData_PeerAssessment1")
unzip
?unzip
unzip(zipfile="activty.zip")
unzip(zipfile="activity.zip")
?unzip
activityDF <- read.csv("activity.csv")
activityDF
str(activityDF)
?read.csv
str(activityDF)
activityDF <- read.csv("activity.csv",stringsAsFactors=FALSE)
str(activityDF)
activityDF <- NULL
activityDF
?str
library(plyr)
?aggregate
str
str(activityDF)
activityDF <- read.csv("activity.csv",stringsAsFactors=FALSE)
names(activityDF)
str(activityDF)
head(activityDF)
is.na(activityDF[1,1])
is.na(activityDF[1,2])
?aggregate
aggregate(steps ~ date, activityDF, mean)
aggregate(steps ~ date, activityDF, FUN=median)
aggregate(steps ~ date, activityDF, median)
